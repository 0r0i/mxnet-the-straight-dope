{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Linear Algebra\n",
    "\n",
    "Now that you can store and manipulate data, let's briefly review the subset of basic linear algebra that you'll need to understand most of the models. We'll introduce all the basic concepts, the corresponding mathematical notaiton, and their realization in code all in one place. If you're already confident basic linear algebra, free to skim or skip this chapter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import mxnet.ndarray as nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalars\n",
    "\n",
    "If you never studied linear algebra or machine learning, you're probably used to working with single numbers, like $42.0$ and know how to do basic things like add them together, multiply them. In mathematical notation, we'll represent salars with ordinary lower cased letters ($x$, $y$, $z$). In MXNet, we can work with scalars by creating NDArrays with just one element. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 5.]\n",
      "<NDArray 1 @cpu(0)>\n",
      "\n",
      "[ 6.]\n",
      "<NDArray 1 @cpu(0)>\n",
      "\n",
      "[ 1.5]\n",
      "<NDArray 1 @cpu(0)>\n",
      "\n",
      "[ 9.]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "x = nd.array([3.0]) \n",
    "y = nd.array([2.0])\n",
    "print(x + y)\n",
    "print(x * y)\n",
    "print(x / y)\n",
    "print(nd.power(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert NDArrays to Python floats by calling their ``.asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.asscalar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectors \n",
    "You can think of vectors are simply a list of numbers ([1.0,3.0,4.0,2.0]). A vector could represent numerical features of some real-world person or object, like the last-record measurements across various vital signs for a patient in the hospital. In math notation, we'll always denote vectors as bold-faced lower-cased letters ($\\boldsymbol{u}$, $\\boldsymbol{v}$, $\\boldsymbol{w})$. In MXNet, we work with vectors via 1D NDArrays with an arbitrary number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "<NDArray 10 @cpu(0)>\n",
      "\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "<NDArray 10 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "u = nd.zeros(shape=10)\n",
    "v = nd.ones(shape=10)\n",
    "print(u)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can refer to any element of a vector by using a subscript. For example, we can refer to the $4$th element of $\\boldsymbol{u}$ by $u_4$. Note that the element $u_4$ is a scalar, so we don't bold-face the font when referring to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices\n",
    "\n",
    "Just as vectors are an extension of scalars from 0 to 1 dimension, matrices generalization vectors to two dimensions. Matrices, which we'll denote with capital letters ($A$, $B$, $C$) are 2D arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 0.96975976  1.81402123 -0.52853745 -1.52274311]\n",
      " [-1.88908994 -2.51524496  0.65479124 -1.35493255]\n",
      " [-0.45481315 -0.95748407  0.32510808 -0.72485566]\n",
      " [-1.30023408  1.11196363  0.3679345  -0.47827247]\n",
      " [ 1.45342624 -1.17394924  0.24154152 -0.79218465]]\n",
      "<NDArray 5x4 @cpu(0)>\n",
      "\n",
      "[[ 0.47898006  0.93210429  0.96885103 -3.15577412]\n",
      " [-1.02182448  2.19352984 -0.06812762 -0.5385921 ]\n",
      " [-0.31868345 -0.8611334  -0.17634277 -1.8815192 ]\n",
      " [ 0.35655284 -0.72057074  0.74419165 -0.35601574]\n",
      " [ 0.77874237 -0.15963985  0.60878229  1.79744768]]\n",
      "<NDArray 5x4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "A = nd.random_normal(shape=(5,4))\n",
    "B = nd.random_normal(shape=(5,4))\n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrices are useful data structures, they allow us to organize data that has different modalities of variation. For example, returning to the example of medical data, rows in our matrix might correspond to different patients, while columns might correspond to different attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the scalar elements $a_{ij}$ of a matrix A by specifying the indices for the row ($i$) and column ($j$) respectively. Let's grab the element $a_{2,3}$ from the random matrix we initialized above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[-0.72485566]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also grab the vectors corresponding to entire rows $\\boldsymbol{a}_{i,:}$ or columns $\\boldsymbol{a}_{:,j}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[-0.45481315 -0.95748407  0.32510808 -0.72485566]\n",
      "<NDArray 4 @cpu(0)>\n",
      "\n",
      "[-1.52274311 -1.35493255 -0.72485566 -0.47827247 -0.79218465]\n",
      "<NDArray 5 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(A[2,:])\n",
    "print(A[:,3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors \n",
    "\n",
    "Just as vectors generalize scalars, and matrices generalize vectors, we can actually build data structures with even more axes. Tensors, give us a generic way of discussing arrays with an arbitrary number of axes. Vectors, for example are be first-order tensors, and matrices are second-order tensors.\n",
    "\n",
    "We'll have to think will become more important when we start working with images, which arrive as 3D data structures, with axes corresponding to the height, width, and the three (RGB) color channels. But in this chapter, we're going to skip past and make sure you know the basics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Element-wise operations\n",
    "\n",
    "Oftentimes, we want to perform element-wise operations. This means that we perform a scalar operation on the corresponding elements of two vectors. So given any two vectors $\\boldsymbol{u}$ and $\\boldsymbol{v}$ *of the same shape*, and a scalar function $f$, we can perform the operation  we produce vector $\\boldsymbol{c} = f(\\boldsymbol{u},\\boldsymbol{v})$ by setting $c_i \\gets f(u_i, v_i)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "<NDArray 10 @cpu(0)>\n",
      "\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "<NDArray 10 @cpu(0)>\n",
      "\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "<NDArray 10 @cpu(0)>\n",
      "\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "<NDArray 10 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(u)\n",
    "print(v) \n",
    "print(u + v)\n",
    "print(u - v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call element-wise operations on any two tensors of the same shape, including matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot products\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix-vector multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix-matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

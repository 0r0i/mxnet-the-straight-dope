{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Manipulate data the MXNet way with `ndarray`\n",
    "\n",
    "It's impossible to get anything done if we can't manipulate data. So let's start by introducing NDArrays, MXNet's primary tool for storing and transforming data. If you've worked with NumPy before, you'll notice that NDArrays are by design similar to NumPy's multi-dimensional array. However, they confer a few key advantages. First, NDArrays support asynchronous computation on CPU, GPU, and distributed cloud architectures. Second, they provide support for automatic differentiation. These properties make NDArray an ideal library for machine learning, both for researchers and engineers launching production systems.\n",
    "\n",
    "\n",
    "## Getting started\n",
    "\n",
    "In this chapter, we'll get you going with the basic functionality. Don't worry if you don't understand any of the basic math, like element-wise operations or normal distributions. In the next two chapters we'll take another pass at NDArray, teaching you both the math you'll need and how to realize it in code.\n",
    "\n",
    "To get started, let's import `mxnet`. We'll also `ndarray` from `mxnet` for convenience. Weâ€™ll also make a habit of setting a random seed so that you always get the same results that we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "mx.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see how to create an NDArray, without values initialized to 1. Specifically, we'll create a 2D array (also called a *matrix*) with 3 rows and 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[  5.30887333e+25   4.58644987e-41   8.72613889e-38   0.00000000e+00]\n",
      " [  2.10587223e-37   0.00000000e+00   8.40779079e-45   0.00000000e+00]\n",
      " [  0.00000000e+00   1.26116862e-44   1.40129846e-44   4.58644987e-41]]\n",
      "<NDArray 3x4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "x = nd.empty(shape=(3,4))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `empty` method just grabs some memory and hands us back a matrix without setting the values of any of its entries. But typically, we'll want our matrices initialized. Commonly, we want a matrix of all zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.  0.  0.  0.  0.]\n",
       " [ 0.  0.  0.  0.  0.]\n",
       " [ 0.  0.  0.  0.  0.]]\n",
       "<NDArray 3x5 @cpu(0)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nd.zeros(shape=(3,5))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, `ndarray` has a function to create a matrix of all ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.  1.  1.  1.]\n",
       " [ 1.  1.  1.  1.]\n",
       " [ 1.  1.  1.  1.]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nd.ones(shape=(3,4))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we'll want to create arrays whose values are sampled randomly. This is especially common when we intend to use the array as a parameter in a neural network. In this snippet, we initialize with values drawn from a standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.14867957 -0.21776067 -0.49851316  2.22578788]\n",
       " [-0.84815776 -0.68832648  0.07811152  0.84155577]\n",
       " [-0.38241303 -0.61584121 -0.05334064  0.01961165]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = nd.random_normal(shape=(3,4))\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in NumPy, the dimensions of each NDArray are accessible via the `.shape` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also query its size, which is equal to the product of the components of the shape. Together with the precision of the stored values, this tells us how much memory the array occupies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations\n",
    "\n",
    "NDarray supports a large number of standard mathematical operations. Such as element-wise addition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.14867961  0.78223932  0.50148684  3.22578788]\n",
       " [ 0.15184224  0.31167352  1.07811153  1.84155583]\n",
       " [ 0.61758697  0.38415879  0.94665939  1.0196116 ]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.14867957 -0.21776067 -0.49851316  2.22578788]\n",
       " [-0.84815776 -0.68832648  0.07811152  0.84155577]\n",
       " [-0.38241303 -0.61584121 -0.05334064  0.01961165]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.16030109  0.80431789  0.60743314  9.26077652]\n",
       " [ 0.42820305  0.50241619  1.08124328  2.31997347]\n",
       " [ 0.68221325  0.54018629  0.948057    1.01980519]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.exp(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also grab a matrix's transpose compute a proper matrix-matrix product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.65819359 -0.61681694 -1.03198326]\n",
       " [ 1.65819359 -0.61681694 -1.03198326]\n",
       " [ 1.65819359 -0.61681694 -1.03198326]]\n",
       "<NDArray 3x3 @cpu(0)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.dot(x, y.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll explain these opoerations and present even more operators in the [linear algebra](P01-C03-linear-algebra.ipynb) chapter. But for now, we'll stick with the mechanics of working with NDArrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-place operations\n",
    "\n",
    "In the previous example, every time we ran an operation, we allocated new memory to host its results. For example, if we write `y = x + y`, we will dereference the matrix that `y` used to point to and insted point it at the newly allocated memory. We can show this using Python's `id()` function, which tells us precisely which object a variable refers to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(y): 140571994896256\n",
      "id(y): 140571994894576\n"
     ]
    }
   ],
   "source": [
    "print('id(y):', id(y))\n",
    "y = y + x\n",
    "print('id(y):', id(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make better use of memory, we can perform operations in place, reusing already allocated memory. We can specify where to write the results of operations by assigning them with slice notation, e.g., `result[:] = ...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(z): 140572040919864\n",
      "id(z): 140572040919864\n"
     ]
    }
   ],
   "source": [
    "z = nd.zeros_like(x)\n",
    "print('id(z):', id(z))\n",
    "z[:] = x + y\n",
    "print('id(z):', id(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're not planning to re-use ``x``, then we can assign the result to ``x`` itself. There are two ways to do this in MXNet. \n",
    "1. By using slice notation x[:] = x op y\n",
    "2. By using the op-equals operators like `+=`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x += y\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But be careful! This is NOT the same as x = x + y. If we donâ€™t use slice notation then we allocate new memory and assign a reference to the new data to the variable x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing\n",
    "\n",
    "MXNet NDArrays support slicing in all the ridiculous ways you might imagine accessing your data. Here's an example of reading the second and third rows from ``x``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.  1.  1.  1.]]\n",
       "<NDArray 1x4 @cpu(0)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now let's try writing to a specific element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.  1.  1.  1.]\n",
       " [ 1.  1.  9.  1.]\n",
       " [ 1.  1.  1.  1.]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,2] = 9.0\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-dimensional slicing is also supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.  9.]]\n",
       "<NDArray 1x2 @cpu(0)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:2,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.  1.  1.  1.]\n",
       " [ 1.  5.  5.  1.]\n",
       " [ 1.  1.  1.  1.]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:2,1:3] = 5.0\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "You might wonder, what happens if you add a vector ``y`` to a matrix ``X``? These operations, where we compose a low dimensional array ``y`` with a high-dimensional array ``X`` invoke a functionality called broadcasting. Here, the low-dimensional array is duplicated along any axis with dimension ``1`` to match the shape of the high dimesnional array. Consider the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  \n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "<NDArray 3x3 @cpu(0)>\n",
      "y =  \n",
      "[ 0.  1.  2.]\n",
      "<NDArray 3 @cpu(0)>\n",
      "x + y =  \n",
      "[[ 1.  2.  3.]\n",
      " [ 1.  2.  3.]\n",
      " [ 1.  2.  3.]]\n",
      "<NDArray 3x3 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "x = nd.ones(shape=(3,3))\n",
    "print('x = ', x)\n",
    "y = nd.arange(3)\n",
    "print('y = ', y)\n",
    "print('x + y = ', x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `y` is initially of shape (3), MXNet infers its shape to be (1,3), and then broadcasts along the rows to form a (3,3) matrix). You might wonder, why did MXNet choose to interpret `y` as a (1,3) matrix and not (3,1). That's because broadcasting prefers to duplicate along the left most axis. We can alter this behavior by explicitly giving `y` a 2D shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y =  \n",
      "[[ 0.]\n",
      " [ 1.]\n",
      " [ 2.]]\n",
      "<NDArray 3x1 @cpu(0)>\n",
      "x + y =  \n",
      "[[ 1.  1.  1.]\n",
      " [ 2.  2.  2.]\n",
      " [ 3.  3.  3.]]\n",
      "<NDArray 3x3 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "y = y.reshape((3,1))\n",
    "print('y = ', y)\n",
    "print('x + y = ', x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting from MXNet NDArray to NumPy \n",
    "\n",
    "Converting MXNet NDArrays to and from NumPy is easy. The converted arrays do not share memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = x.asnumpy()\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.  1.  1.]\n",
       " [ 1.  1.  1.]\n",
       " [ 1.  1.  1.]]\n",
       "<NDArray 3x3 @cpu(0)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = nd.array(a) \n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing context\n",
    "\n",
    "By far, MXNet NDArray looks almost identical to NumPy. One of the key features make MXNet differs to NumPy is the supporting for various hardware.\n",
    "\n",
    "In MXNet, every array has a context. One context could be the CPU. Other contexts might be various GPUs. Things can get even hairier when we deploy jobs across multiple servers. By assigning arrays to contexts intelligently, we can minimize the time spent transferring data between devices. For example, when training neural networks on a server with a GPU, we typically prefer for the model's parameters to live on the GPU. To start, let's try initializing an array on the first GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.  1.  1.]\n",
       " [ 1.  1.  1.]\n",
       " [ 1.  1.  1.]]\n",
       "<NDArray 3x3 @gpu(0)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet import gpu\n",
    "z = nd.ones(shape=(3,3), ctx=gpu(0))\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an NDArray on a given context, we can copy it to another context by using the ``copyto()`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "<NDArray 3x3 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "x_gpu = x.copyto(gpu(0))\n",
    "print(x_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of an operator will have the same context as the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 2.  2.  2.]\n",
       " [ 2.  2.  2.]\n",
       " [ 2.  2.  2.]]\n",
       "<NDArray 3x3 @gpu(0)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_gpu + z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch out!\n",
    "\n",
    "Imagine that your variable ``z`` already lives on your second GPU (``gpu(0)``). What happens if we call ``z.copyto(gpu(0))``? It will make a copy and allocate new memory, even though that variable already lives on the desired device! \n",
    "\n",
    "Often, we only want to make a copy if the variable *currently* lives in the wrong context. In these cases, we can call ``as_in_context()``. If the variable is already on ``gpu(0)`` then this is a no-op."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(z): 140571939657432\n",
      "id(z): 140572040919864\n",
      "id(z): 140572040919864\n",
      "\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "<NDArray 3x3 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print('id(z):', id(z))\n",
    "z = z.copyto(gpu(0))\n",
    "print('id(z):', id(z))\n",
    "z = z.as_in_context(gpu(0))\n",
    "print('id(z):', id(z))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For whinges or inquiries, [open an issue on  GitHub.](https://github.com/zackchase/mxnet-the-straight-dope)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

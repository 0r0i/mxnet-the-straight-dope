{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Generative Adversarial Networks\n",
    "\n",
    "[Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434) is a model which is capable of learning resuable feature representations from large unlabeled image datasets. It helps bridge the gap between the success of CNNs for supervised learning and unsupervised learning. \n",
    "\n",
    "In this tutorial, we'll use DCGAN model to train on [LWF Face Dataset](http://vis-www.cs.umass.edu/lfw/). We'll see that good image representation can be built by GAN and our model is capable of generating photo-realistic human face images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import tarfile\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet import ndarray as nd\n",
    "from mxnet.gluon import nn, utils\n",
    "from mxnet import autograd\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "latent_z_size = 100\n",
    "ctx = [mx.cpu()]\n",
    "\n",
    "lr = 0.0002\n",
    "beta1 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and preprocess LWF Face Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lwf_url = 'http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz'\n",
    "data_path = 'lwf_dataset'\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "    data_file = utils.download(lwf_url)\n",
    "    with tarfile.open(data_file) as tar:\n",
    "        tar.extractall(path=data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first resize images to size 64*64. Then normalize image pixel values to be between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_wd = 64\n",
    "target_ht = 64\n",
    "img_list = []\n",
    "for path, _, fnames in os.walk(data_path):\n",
    "    for fname in fnames:\n",
    "        if not fname.endswith('.jpg'):\n",
    "            continue\n",
    "        img = os.path.join(path, fname)\n",
    "        img_arr = cv2.imread(img)\n",
    "        # resize image to 64*64\n",
    "        ht, wd = img_arr.shape[:2]\n",
    "        interpolation = cv2.INTER_AREA if ht > target_ht and wd > target_wd \\\n",
    "            else cv2.INTER_LINEAR\n",
    "        resized_img = cv2.resize(img_arr, (target_ht, target_wd), interpolation=interpolation)\n",
    "        # normalize image pixel value to between -1 and 1\n",
    "        normalized_img = np.array(resized_img/127.5 - 1)\n",
    "        img_list.append(np.rollaxis(normalized_img, 2, 0))\n",
    "train_data = mx.io.NDArrayIter(data=nd.array(img_list), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the networks\n",
    "\n",
    "The core to DCGAN architecture is adopting and modifying CNN architecture:\n",
    "* Replace any pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator).\n",
    "\n",
    "* Use batchnorm in both the generator and the discriminator.\n",
    "\n",
    "* Remove fully connected hidden layers for deeper architectures.\n",
    "\n",
    "* Use ReLU activation in generator for all layers except for the output, which uses Tanh.\n",
    "\n",
    "* Use LeakyReLU activation in the discriminator for all layers.\n",
    "\n",
    "![alt text](img/dcgan.png \"DCGAN Architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build the generator\n",
    "nc = 3\n",
    "ngf = 64\n",
    "netG = nn.Sequential()\n",
    "with netG.name_scope():\n",
    "    # input is Z, going into a convolution\n",
    "    netG.add(nn.Conv2DTranspose(ngf * 8, 4, 1, 0, use_bias=False))\n",
    "    netG.add(nn.BatchNorm())\n",
    "    netG.add(nn.Activation('relu'))\n",
    "    # state size. (ngf*8) x 4 x 4\n",
    "    netG.add(nn.Conv2DTranspose(ngf * 4, 4, 2, 1, use_bias=False))\n",
    "    netG.add(nn.BatchNorm())\n",
    "    netG.add(nn.Activation('relu'))\n",
    "    # state size. (ngf*8) x 8 x 8\n",
    "    netG.add(nn.Conv2DTranspose(ngf * 2, 4, 2, 1, use_bias=False))\n",
    "    netG.add(nn.BatchNorm())\n",
    "    netG.add(nn.Activation('relu'))\n",
    "    # state size. (ngf*8) x 16 x 16\n",
    "    netG.add(nn.Conv2DTranspose(ngf, 4, 2, 1, use_bias=False))\n",
    "    netG.add(nn.BatchNorm())\n",
    "    netG.add(nn.Activation('relu'))\n",
    "    # state size. (ngf*8) x 32 x 32\n",
    "    netG.add(nn.Conv2DTranspose(nc, 4, 2, 1, use_bias=False))\n",
    "    netG.add(nn.Activation('tanh'))\n",
    "    # state size. (nc) x 64 x 64\n",
    "\n",
    "# build the discriminator\n",
    "ndf = 64\n",
    "netD = nn.Sequential()\n",
    "with netD.name_scope():\n",
    "    # input is (nc) x 64 x 64\n",
    "    netD.add(nn.Conv2D(ndf, 4, 2, 1, use_bias=False))\n",
    "    netD.add(nn.LeakyReLU(0.2))\n",
    "    # state size. (ndf) x 32 x 32\n",
    "    netD.add(nn.Conv2D(ndf * 2, 4, 2, 1, use_bias=False))\n",
    "    netD.add(nn.BatchNorm())\n",
    "    netD.add(nn.LeakyReLU(0.2))\n",
    "    # state size. (ndf) x 16 x 16\n",
    "    netD.add(nn.Conv2D(ndf * 4, 4, 2, 1, use_bias=False))\n",
    "    netD.add(nn.BatchNorm())\n",
    "    netD.add(nn.LeakyReLU(0.2))\n",
    "    # state size. (ndf) x 8 x 8\n",
    "    netD.add(nn.Conv2D(ndf * 8, 4, 2, 1, use_bias=False))\n",
    "    netD.add(nn.BatchNorm())\n",
    "    netD.add(nn.LeakyReLU(0.2))\n",
    "    # state size. (ndf) x 4 x 4\n",
    "    netD.add(nn.Conv2D(2, 4, 1, 0, use_bias=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Loss Function and Optimizer\n",
    "We use softmax cross entropy as loss function and adam as optimizer. Initialize parameters with normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loss\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "# initialize the generator and the discriminator\n",
    "netG.initialize(mx.init.Normal(0.02), ctx=ctx)\n",
    "netD.initialize(mx.init.Normal(0.02), ctx=ctx)\n",
    "\n",
    "# trainer for the generator and the discriminator\n",
    "trainerG = gluon.Trainer(netG.collect_params(), 'adam', {'learning_rate': lr, 'beta1': beta1})\n",
    "trainerD = gluon.Trainer(netD.collect_params(), 'adam', {'learning_rate': lr, 'beta1': beta1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import logging\n",
    "\n",
    "real_label = utils.split_and_load(mx.nd.ones((batch_size,)), ctx)\n",
    "fake_label = utils.split_and_load(mx.nd.zeros((batch_size,)), ctx)\n",
    "metric = mx.metric.Accuracy()\n",
    "stamp =  datetime.now().strftime('%Y_%m_%d-%H_%M')\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "iter = 0\n",
    "for epoch in range(epochs):\n",
    "    tic = time.time()\n",
    "    btic = time.time()\n",
    "    for batch in train_data:\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        data = utils.split_and_load(batch.data[0], ctx)\n",
    "        latent_z = utils.split_and_load(mx.nd.random_normal(0, 1, shape=(batch_size, latent_z_size, 1, 1)), ctx)\n",
    "\n",
    "        with autograd.record():\n",
    "            # train with real image\n",
    "            outputs = [netD(data_slice).reshape((batch.data[0].shape[0], 2)) for data_slice in data]\n",
    "            errD_real = [loss(output, r_label_slice) for output, r_label_slice in zip(outputs, real_label)]\n",
    "            metric.update(real_label, outputs)\n",
    "\n",
    "            # train with fake image\n",
    "            fakes = [netG(latent_z_slice) for latent_z_slice in latent_z]\n",
    "            outputs = [netD(fake_slice).reshape((batch.data[0].shape[0], 2)) for fake_slice in fakes]\n",
    "            errD_fake = [loss(output, f_label_slice) for output, f_label_slice in zip(outputs, fake_label)]\n",
    "            errD = [errD_r + errD_f for errD_r, errD_f in zip(errD_real, errD_fake)]\n",
    "            for err in errD:\n",
    "                err.backward()\n",
    "            metric.update(fake_label, outputs)\n",
    "\n",
    "        trainerD.step(batch.data[0].shape[0])\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        with autograd.record():\n",
    "            outputs = [netD(fake_slice).reshape((batch.data[0].shape[0], 2)) for fake_slice in fakes]\n",
    "            errG = [loss(output, r_label_slice) for output, r_label_slice in zip(outputs, real_label)]\n",
    "            for err in errG:\n",
    "                err.backward()\n",
    "\n",
    "        trainerG.step(batch.data[0].shape[0])\n",
    "\n",
    "        name, acc = metric.get()\n",
    "        # logging.info('speed: {} samples/s'.format(opt.batch_size / (time.time() - btic)))\n",
    "        logging.info('discriminator loss = %f, generator loss = %f, binary training acc = %f at iter %d epoch %d' \n",
    "                     %(nd.mean(nd.concatenate(errD)).asscalar(), \n",
    "                       nd.mean(nd.concatenate(errG)).asscalar(), acc, iter, epoch))\n",
    "        if iter % 1 == 0:\n",
    "            #visual('gout', fake.asnumpy(), name=os.path.join(outf,'fake_img_iter_%d.png' %iter))\n",
    "            #visual('data', data.asnumpy(), name=os.path.join(outf,'real_img_iter_%d.png' %iter))\n",
    "            pass\n",
    "\n",
    "        iter = iter + 1\n",
    "        btic = time.time()\n",
    "\n",
    "    name, acc = metric.get()\n",
    "    metric.reset()\n",
    "    logging.info('\\nbinary training acc at epoch %d: %s=%f' % (epoch, name, acc))\n",
    "    logging.info('time: %f' % (time.time() - tic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
